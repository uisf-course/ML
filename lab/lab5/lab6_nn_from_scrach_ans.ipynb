{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c95e3b7e-57db-4225-8af7-85e82676ae33",
      "metadata": {
        "id": "c95e3b7e-57db-4225-8af7-85e82676ae33"
      },
      "source": [
        "## Notebook Objectives\n",
        "\n",
        "\n",
        "In this notebook we are going to implement and train a neural network from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f68f50b8-2074-4636-a4ff-d1fcc82c6b10",
      "metadata": {
        "id": "f68f50b8-2074-4636-a4ff-d1fcc82c6b10"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "833d8a57-2bfd-4221-a999-1dc66351a6ea",
      "metadata": {
        "id": "833d8a57-2bfd-4221-a999-1dc66351a6ea"
      },
      "source": [
        "## Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da63486d-1664-4cc5-9c3f-8908d9a6e9bc",
      "metadata": {
        "id": "da63486d-1664-4cc5-9c3f-8908d9a6e9bc"
      },
      "source": [
        "### Abstract Layer Class"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27e3ad52-bc7e-4cd4-916c-2c385b069a36",
      "metadata": {
        "id": "27e3ad52-bc7e-4cd4-916c-2c385b069a36"
      },
      "source": [
        "The Layer class serves as an abstract base class for all layers in the network. It includes placeholder methods:\n",
        "\n",
        "-forward: The forward pass computes the output of the layer given an input.\n",
        "-backward: The backward pass computes the gradients with respect to the input and parameters.\n",
        "-step: Updates the layer parameters (weights and biases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edb940f4-9acf-47d1-803e-39be070b28da",
      "metadata": {
        "id": "edb940f4-9acf-47d1-803e-39be070b28da"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.inp = None\n",
        "        self.out = None\n",
        "\n",
        "    def __call__(self, inp: np.ndarray) -> np.ndarray:\n",
        "        return self.forward(inp)\n",
        "\n",
        "    def forward(self, inp: np.ndarray) -> np.ndarray:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, up_grad: np.ndarray) -> np.ndarray:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def step(self, lr: float) -> None:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "945f875c-08f3-407c-94b4-8bf9b9a9f5fe",
      "metadata": {
        "id": "945f875c-08f3-407c-94b4-8bf9b9a9f5fe"
      },
      "source": [
        "## Linear Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49132b5e-051e-45b8-81a3-06938b9645e8",
      "metadata": {
        "id": "49132b5e-051e-45b8-81a3-06938b9645e8"
      },
      "source": [
        "The Linear class implements the fully connected (or dense) layer of a neural network, which performs a linear transformation on the input:\n",
        "\n",
        "$$\\mathbf{y} = \\mathbf{x} \\cdot \\mathbf{W} + \\mathbf{b}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63e2f81c-274d-4e7c-be03-a477c4b7da84",
      "metadata": {
        "id": "63e2f81c-274d-4e7c-be03-a477c4b7da84"
      },
      "source": [
        "**Initialization**\n",
        "- `self.w`: Represents the weight matrix of shape `(in_dim, out_dim)`, initialized using small random values.\n",
        "- `self.b`: Bias vector of shape `(1, out_dim)`, initialized to zeros.\n",
        "- `self.dw` and `self.db`: These store the computed gradients of weights and biases during backpropagation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Forward Pass**\n",
        "- The forward pass computes:\n",
        "$$\\mathbf{out} = \\mathbf{inp} \\cdot \\mathbf{W} + \\mathbf{b}$$\n",
        "where:\n",
        "  - `inp`: Input matrix of shape `(batch_size, in_dim)`\n",
        "  - `self.w`: Weight matrix of shape `(in_dim, out_dim)`\n",
        "  -\t`self.b`: Bias matrix of shape `(1, out_dim)`\n",
        "-\tThe result is a matrix out of shape `(batch_size, out_dim)`.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Backward Pass**\n",
        "- The backward pass computes gradients needed for updating the weights and biases. Given the upstream gradient `up_grad` (from the loss with respect to the output of this layer), we calculate:\n",
        "  - Gradient w.r.t. weights (`self.dw`):\n",
        "    $$\\frac{\\partial L}{\\partial W} = \\mathbf{inp}^T\\cdot\\text{up\\_grad}$$\n",
        "  - Gradient w.r.t. biases (`self.db`):\n",
        "    $$\\frac{\\partial L}{\\partial b} = \\sum \\text{up\\_grad} \\text{ (summed across batch)}$$\n",
        "  - Gradient to propagate to the previous layer (`down_grad`):\n",
        "    $$\\text{down\\_grad} = \\text{up\\_grad} \\cdot W^T$$\n",
        "- This allows the gradient to flow backward to earlier layers.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Step Method**\n",
        "- Updates the weights and biases using the computed gradients and learning rate (`lr`):\n",
        "    $$W = W - lr \\cdot \\frac{\\partial L}{\\partial W}$$\n",
        "    $$b = b - lr \\cdot \\frac{\\partial L}{\\partial b}$$"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LtisuWclgoE5"
      },
      "id": "LtisuWclgoE5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7998bbc-d128-422a-9580-7d3da25b3888",
      "metadata": {
        "id": "e7998bbc-d128-422a-9580-7d3da25b3888"
      },
      "outputs": [],
      "source": [
        "class Linear(Layer) :\n",
        "    def __init__(self, in_dim, out_dim) :\n",
        "        #Xiavier initialization\n",
        "        limit = np.sqrt(1/(in_dim + out_dim))\n",
        "        self.w = np.random.uniform(-limit, limit, size=(in_dim, out_dim))\n",
        "        self.b = np.zeros((1,out_dim))\n",
        "        self.dw = np.zeros_like(self.w)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "\n",
        "    def forward(self, inp:np.ndarray) -> np.ndarray :\n",
        "        \"\"\"Perform the linear transformation: output = inp * W + b\"\"\"\n",
        "        self.inp = inp\n",
        "        return np.dot(inp, self.w) + self.b\n",
        "\n",
        "    def backward(self, up_grade:np.ndarray)-> np.ndarray :\n",
        "        self.dw = np.dot(self.inp.T, up_grade)\n",
        "        self.db = np.sum(up_grade, axis=0, keepdims = True)\n",
        "        return np.dot(up_grade,self.w.T)\n",
        "\n",
        "    def step(self, lr:float) -> None :\n",
        "        self.w -= self.dw * lr\n",
        "        self.b -= self.db * lr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1596a7a-eefd-411d-b3ea-7c21272f3ccb",
      "metadata": {
        "id": "b1596a7a-eefd-411d-b3ea-7c21272f3ccb"
      },
      "source": [
        "## Activation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17039109-b496-4483-bc22-e06f257ce949",
      "metadata": {
        "id": "17039109-b496-4483-bc22-e06f257ce949"
      },
      "source": [
        "We can implement activation functions as layers. This will simplify the training process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c273985-c8a9-4edf-9e60-a42e45750712",
      "metadata": {
        "id": "2c273985-c8a9-4edf-9e60-a42e45750712"
      },
      "source": [
        "### Sigmoid\n",
        "\n",
        "- The Sigmoid function is defined as follows:\n",
        "\n",
        "$$f(x) = \\frac{1}{1 + e^{-x}}$$\n",
        "\n",
        "- Sigmoid squashes the input into the range [0, 1], making it useful for binary classification tasks.\n",
        "- It converts any real-valued number into a probability-like output.\n",
        "- However, in deeper networks, it may cause vanishing gradients due to its flat slope for extreme values.\n",
        "- The derivative of Sigmoid is convenient to compute using its output  $f(x)$:\n",
        "$$f'(x) = \\frac{-e^{-x}}{(1 + e^{-x})^2} = \\frac{1}{1 + e^{-x}} \\cdot \\frac{e^{-x}}{1 + e^{-x}} = f(x) \\cdot (1-f(x))$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a492a3-b84e-43fc-8ffd-14de45dd54da",
      "metadata": {
        "id": "c7a492a3-b84e-43fc-8ffd-14de45dd54da"
      },
      "outputs": [],
      "source": [
        "class Sigmoid(Layer) :\n",
        "    def forward(self, inp:np.ndarray) -> np.ndarray :\n",
        "\n",
        "        self.out = 1 / (1 + np.exp(-inp))\n",
        "        return self.out\n",
        "    def backward(self, up_grad : np.ndarray) -> np.ndarray :\n",
        "        return  self.out *(1-self.out) * up_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c334bc45-5f15-4ba1-99c1-43ac29a6130d",
      "metadata": {
        "id": "c334bc45-5f15-4ba1-99c1-43ac29a6130d"
      },
      "outputs": [],
      "source": [
        "class Relu(Layer) :\n",
        "    def forward(self, inp) :\n",
        "        self.inp = inp\n",
        "        out = np.maximum(0, inp) # maximum performs element-wise maximum\n",
        "        return out\n",
        "    def backward(self, up_grad) :\n",
        "        return up_grad * (self.inp > 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc3414ec-803a-4000-8422-3417fde7c2b0",
      "metadata": {
        "id": "bc3414ec-803a-4000-8422-3417fde7c2b0"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5129d8ba-07c4-4023-9792-9490496adae8",
      "metadata": {
        "id": "5129d8ba-07c4-4023-9792-9490496adae8"
      },
      "source": [
        "### Abstract Loss Class\n",
        "\n",
        "The `Loss` class serves as an abstract base class for all layers in the network. It includes placeholder methods:\n",
        "- `forward`: To compute the loss given predictions and targets.\n",
        "- `backward`: To compute the loss given predictions and targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0961720e-fad3-4f23-a602-ca873d8c2a4d",
      "metadata": {
        "id": "0961720e-fad3-4f23-a602-ca873d8c2a4d"
      },
      "outputs": [],
      "source": [
        "class Loss:\n",
        "    def __init__(self):\n",
        "        self.prediction = None\n",
        "        self.target = None\n",
        "        self.loss = None\n",
        "\n",
        "    def __call__(self, prediction: np.ndarray, target: np.ndarray) -> float:\n",
        "        return self.forward(prediction, target)\n",
        "\n",
        "    def forward(self, prediction: np.ndarray, target: np.ndarray) -> float:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self) -> np.ndarray:\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e979cbc0-5963-469a-9844-d11d04f0d5a6",
      "metadata": {
        "id": "e979cbc0-5963-469a-9844-d11d04f0d5a6"
      },
      "source": [
        "## Mean Squared Error (MSE) Loss\n",
        "\n",
        "MSE is used primarily for regression tasks, where you need to measure the distance between the predicted continuous values and the true values:\n",
        "\n",
        "$$L = \\frac{1}{N} \\sum_{i} (p_i - y_i)^2$$\n",
        "\n",
        "where $p_i$ is the predicted value, $y_i$ is the true value (target) and $N$ is the batch size.\n",
        "\n",
        "The gradient measures the difference between the prediction and the target, scaled by the batch size:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial p_i} = \\frac{2}{N} (p_i - y_i)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b75a1f1c-6629-40b9-9b5a-68fe15e9eaaa",
      "metadata": {
        "id": "b75a1f1c-6629-40b9-9b5a-68fe15e9eaaa"
      },
      "outputs": [],
      "source": [
        "class MSE(Loss) :\n",
        "    def forward(self, prediction, target) :\n",
        "        self.prediction = prediction\n",
        "        self.target = target\n",
        "        self.loss = np.mean((prediction-target)**2)\n",
        "        return self.loss\n",
        "    def backward(self) :\n",
        "        return 2 * (self.prediction-self.target) / len(self.prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdfd07cb-44b0-4b5d-b429-a1b59ad0aa8a",
      "metadata": {
        "id": "cdfd07cb-44b0-4b5d-b429-a1b59ad0aa8a"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b2ae071-a1d1-4d8a-96a0-d0ddff3cdd51",
      "metadata": {
        "id": "6b2ae071-a1d1-4d8a-96a0-d0ddff3cdd51"
      },
      "source": [
        "Now we can combine everything we've done earlier to build a neural network class called `MLP` with the following methods:\n",
        "\n",
        "- `forward`: Sequentially passes input through each layer in the network to compute the output.\n",
        "- `loss`: Computes the loss between the predicted output and the true target using the specified loss function.\n",
        "- `backward`: Propagates the gradient from the loss function through each layer, updating the gradients of the parameters in each layer.\n",
        "- `update`: Updates each layer's parameters (e.g., weights and biases) using the gradients computed during backpropagation.\n",
        "- `train`: Executes the training loop for a specified number of epochs, iterating over the dataset in mini-batches, performing the forward pass, computing the loss, backpropagating the gradients, and updating the parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1028b4b2-7de1-48ac-843d-43c5ce778b2c",
      "metadata": {
        "id": "1028b4b2-7de1-48ac-843d-43c5ce778b2c"
      },
      "outputs": [],
      "source": [
        "class MLP :\n",
        "    def __init__ (self, layers:list[Layer], loss_fun:Loss, lr:float) -> None :\n",
        "        \"\"\"\n",
        "        Multi-Layer Perceptron (MLP) class.\n",
        "        Arguments:\n",
        "        - layers: List of layers (e.g., Linear, ReLU, etc.).\n",
        "        - loss_fn: Loss function object (e.g., CrossEntropy, MSE).\n",
        "        - lr: Learning rate.\n",
        "        \"\"\"\n",
        "        self.layers = layers\n",
        "        self.loss_fun = loss_fun\n",
        "        self.lr = lr\n",
        "\n",
        "    def __call__(self, inp) :\n",
        "        self.forward(inp)\n",
        "\n",
        "    def forward(self, inp) :\n",
        "        for layer in self.layers :\n",
        "          inp = layer.forward(inp)\n",
        "        return inp\n",
        "\n",
        "    def loss(self, prediction, target) :\n",
        "        return self.loss_fun(prediction, target)\n",
        "\n",
        "    def backward(self) :\n",
        "        up_grad = self.loss_fun.backward()\n",
        "        for layer in reversed(self.layers) :\n",
        "            up_grad = layer.backward(up_grad)\n",
        "\n",
        "    def update(self) :\n",
        "        for layer in self.layers :\n",
        "          layer.step(self.lr)\n",
        "\n",
        "    def train(self, x_train, y_train, x_val, y_val, epochs, batch_size):\n",
        "        \"\"\"Train the MLP over the given dataset for a number of epochs.\"\"\"\n",
        "        losses = np.empty(epochs)\n",
        "\n",
        "        for epoch in range(epochs) :\n",
        "          running_loss = 0\n",
        "          for i in range(0, len(x_train), batch_size) :\n",
        "            x_batch = x_train[i:i+batch_size]\n",
        "            y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "            prediction = self.forward(x_batch)\n",
        "            running_loss += self.loss(prediction, y_batch) * batch_size\n",
        "            self.backward()\n",
        "            self.update()\n",
        "          losses[epoch] = running_loss / len(x_train)\n",
        "        return losses\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "776af4a2-d9ed-490c-9e65-eb637b27aa21",
      "metadata": {
        "id": "776af4a2-d9ed-490c-9e65-eb637b27aa21"
      },
      "source": [
        "## Regression training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0635e46-fde4-41d0-9dcf-ef0cfa225fd4",
      "metadata": {
        "id": "c0635e46-fde4-41d0-9dcf-ef0cfa225fd4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load California Housing dataset\n",
        "california = fetch_california_housing()\n",
        "X = california.data\n",
        "y = california.target.reshape(-1, 1)\n",
        "\n",
        "                              # Normalize features and targets\n",
        "scaler_X = StandardScaler() # a preprocessing tool from scikit-learn that standardizes features by removing the mean and scaling to unit variance.\n",
        "scaler_y = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_scaled, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc2f2eb-8dd2-401a-a938-62cfadd6737c",
      "metadata": {
        "id": "3bc2f2eb-8dd2-401a-a938-62cfadd6737c"
      },
      "outputs": [],
      "source": [
        "#define layers\n",
        "layers = [\n",
        "    Linear(X_train.shape[1], 50),\n",
        "    Relu(),\n",
        "    Linear(50, 1)\n",
        "]\n",
        "#define model\n",
        "model = MLP(layers, MSE(), lr=0.001)\n",
        "losses = model.train(X_train,y_train,X_test,y_test,500, 64)\n",
        "#train_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88a72941-b751-4ae0-89b7-61548e9f10de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "88a72941-b751-4ae0-89b7-61548e9f10de",
        "outputId": "c839d163-0135-45a6-a4e7-280df39171aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a368a12ebd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#plot losses\n",
        "plt.plot(losses)\n",
        "\n",
        "#plot train and validation loss"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}